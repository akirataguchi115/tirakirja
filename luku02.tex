\chapter{Tehokkuus}

Algoritmien suunnittelussa tavoitteena on saada aikaan
algoritmeja, jotka toimivat \emph{tehokkaasti}.
Haluamme luoda algoritmeja, joiden avulla voidaan
käsitellä myös suuria aineistoja ilman,
että algoritmin suoritus kestää kauan.
Ajattelemmekin, että algoritmi on \emph{hyvä},
jos se antaa nopeasti vastauksen myös silloin,
kun tiedon määrä on suuri.

Tässä luvussa tutustumme työkaluihin, joiden avulla
voimme arvioida algoritmien tehokkuutta.
Keskeinen käsite on \emph{aikavaativuus}, joka antaa
tiiviissä muodossa kuvauksen algoritmin ajankäytöstä.
Aikavaativuuden avulla voimme muodostaa arvion
algoritmin tehokkuudesta sen rakenteen perusteella,
eikä meidän tarvitse toteuttaa ja testata algoritmia
vain saadaksemme tietää, miten nopea se on.

\section{Aikavaativuus}

\index{aikavaativuus}

Algoritmin tehokkuus riippuu siitä, montako askelta se suorittaa.
Tavoitteemme on nyt arvioida algoritmin askelten määrää
suhteessa syötteen kokoon $n$.
Esimerkiksi jos syötteenä on taulukko,
$n$ on taulukon koko,
ja jos syötteenä on merkkijono,
$n$ on merkkijonon pituus.

Tarkastellaan esimerkkinä seuraavaa algoritmia,
joka laskee, montako kertaa alkio $x$ esiintyy
$n$ lukua sisältävässä taulukossa.

\begin{code}[numbers=left]
laskuri = 0
for i = 0 to n-1
    if luvut[i] == x
        laskuri += 1
\end{code}

Voimme arvioida algoritmin tehokkuutta tutkimalla
jokaisesta rivistä, montako kertaa algoritmi suorittaa sen.
Rivi 1 suoritetaan vain kerran algoritmin alussa.
Tämän jälkeen alkaa silmukka, jossa
rivit 2 ja 3 suoritetaan molemmat $n$ kertaa
ja rivi 4 puolestaan suoritetaan $0 \dots n$
kertaa riippuen siitä, kuinka usein
luku $x$ esiintyy taulukossa.
Algoritmi suorittaa siis vähintään $2n+1$ ja enintään $3n+1$
askelta.

\index{$O$-merkintä}

Näin tarkka analyysi ei ole kuitenkaan yleensä tarpeen,
vaan riittää määrit\-tää karkea \emph{yläraja} ajankäytölle.
Algoritmi toimii ajassa $O(f(n))$ eli sen
\emph{aikavaativuus} (\emph{time complexity}) on $O(f(n))$, jos se suorittaa
enintään $c f(n)$ askelta aina silloin kun $n \ge n_0$,
missä $c$ ja $n_0$ ovat vakioita.
Esimerkiksi äskeinen algoritmi toimii ajassa $O(n)$,
koska se suorittaa enintään $4n$ askelta
kaikilla $n$:n arvoilla eli voidaan valita $c=4$ ja $n_0=1$.

\subsection{Laskusääntöjä}

Aikavaativuuden mukavana puolena on, että voimme yleensä
päätellä aikavaativuuden helposti algoritmin
rakenteesta. Tutustumme seuraavaksi laskusääntöihin,
joiden avulla tämä on mahdollista.

\subsubsection{Yksittäiset komennot}

Jos koodissa ei ole silmukoita vaan vain
yksittäisiä komentoja, sen aikavaativuus on $O(1)$.
Näin on esimerkiksi seuraavassa koodissa:

\begin{code}
c = a+b
if c >= 0
    print(c)
\end{code}

\subsubsection{Silmukat}

Merkitsemme \texttt{...} koodia,
jonka aikavaativuus on $O(1)$.
Jos koodissa on yksi silmukka,
joka suorittaa $n$ askelta,
sen aikavaativuus on $O(n)$:

\begin{code}
for i = 1 to n
    ...
\end{code}

Jos tällaisia silmukoita on kaksi sisäkkäin,
aikavaativuus on $O(n^2)$:

\begin{code}
for i = 1 to n
    for j = 1 to n
        ...
\end{code}

Yleisemmin jos koodissa on vastaavalla tavalla
$k$ sisäkkäistä silmukkaa, sen aikavaativuus on $O(n^k)$.

\index{vakiokerroin}

Huomaa, että vakiokertoimet ja matalammat termit eivät vaikuta aikavaativuuteen.
Esimerkiksi seuraavissa koodeissa silmukoissa on $2n$ ja $n-1$ askelta,
mutta kummankin koodin aikavaativuus on $O(n)$.

\begin{code}
for i = 1 to 2*n
    ...
\end{code}

\begin{code}
for i = 1 to n-1
    ...
\end{code}

\subsubsection{Peräkkäiset osuudet}

Jos koodissa on peräkkäisiä osuuksia, sen aikavaativuus on suurin
yksittäisen osuuden aikavaativuus. Esimerkiksi seuraavan koodin aikavaativuus on $O(n^2)$,
koska sen osuuksien aikavaativuudet ovat $O(n)$, $O(n^2)$ ja $O(n)$.

\begin{code}
for i = 1 to n
    ...
for i = 1 to n
    for j = 1 to n
        ...
for i = 1 to n
    ...
\end{code}

\subsubsection{Monta muuttujaa}

Joskus aikavaativuus riippuu useammasta asiasta,
jolloin kaavassa on monta muuttujaa.
Esimerkiksi seuraavan koodin aikavaativuus on $O(nm)$:

\begin{code}
for i = 1 to n
    for j = 1 to m
        ...
\end{code}

\subsubsection{Rekursiiviset algoritmit}

Rekursiivisessa algoritmissa laskemme,
montako rekursiivista kutsua teh\-dään ja kauanko
yksittäinen kutsu vie aikaa.
Tarkastellaan esimerkkinä seuraavaa
proseduuria, jota kutsutaan parametrilla $n$:

\begin{code}
procedure f(n)
    if n == 1
        return
    f(n-1)
\end{code}

Proseduuria kutsutaan yhteensä $n$ kertaa ja jokainen kutsu vie aikaa $O(1)$.
Saamme selville proseduurin aikavaativuuden kertomalla nämä arvot keskenään,
joten proseduuri vie aikaa $O(n)$.

Tarkastellaan sitten seuraavaa proseduuria:

\begin{code}
procedure g(n)
    if n == 1
        return
    g(n-1)
    g(n-1)
\end{code}

Tässä tapauksessa jokainen proseduurin kutsu tuottaa kaksi uutta kutsua,
joten proseduuria kutsutaan kaikkiaan
\[1+2+4+\dots+2^{n-1}=2^n-1\]
kertaa. Jokainen kutsu vie aikaa $O(1)$,
joten aikavaativuus on $O(2^n)$.

\subsection{Yleisiä aikavaativuuksia}

Tietyt aikavaativuudet esiintyvät usein algoritmeissa.
Käymme seuraavaksi läpi joukon tällaisia aikavaativuuksia.

\index{vakioaikainen algoritmi}

\subsubsection{$O(1)$ (vakioaikainen)}

\emph{Vakioaikainen} (\emph{constant time}) algoritmi suorittaa kiinteän määrän komentoja,
eikä syötteen suuruus vaikuta algoritmin nopeuteen.
Esimerkiksi seuraava algoritmi laskee summan $1+2+\dots+n$
vakioajassa summakaavalla:

\begin{code}
summa = n*(n+1)/2
\end{code}

\index{logaritminen algoritmi}

\subsubsection{$O(\log n)$ (logaritminen)}

\emph{Logaritminen} (\emph{logarithmic}) algoritmi puolittaa usein syötteen koon
joka askeleella.
Esimerkiksi seuraavan algoritmin aikavaativuus on $O(\log n)$:

\begin{code}
laskuri = 0
while n >= 1
    laskuri += 1
    n /= 2
\end{code}

Tärkeä seikka logaritmeihin liittyen on, että
$\log n$ on \emph{pieni} luku, kun $n$ on mikä tahansa 
tyypillinen algoritmeissa esiintyvä luku.
Esimerkiksi $\log 10^6 \approx 20$ ja $\log 10^9 \approx 30$,
kun logaritmin kantaluku on 2.
Niinpä jos algoritmi tekee jotain logaritmisessa ajassa,
siinä ei kulu kauan aikaa.

\index{lineaarinen algoritmi}

\subsubsection{$O(n)$ (lineaarinen)}

\emph{Lineaarinen} (\emph{linear}) algoritmi voi käydä läpi syötteen kiinteän määrän kertoja.
Esimerkiksi seuraava $O(n)$-algoritmi laskee taulukon lukujen summan:

\begin{code}
summa = 0
for i = 0 to n-1
    summa += taulu[i]
\end{code}

Kun algoritmin syötteenä on aineisto, jossa on $n$ alkiota,
lineaarinen aikavaativuus on yleensä paras mahdollinen,
minkä voimme saavuttaa.
Tämä johtuu siitä, että algoritmin täytyy käydä syöte
ainakin kerran läpi, ennen kuin se voi ilmoittaa vastauksen.

\subsubsection{$O(n \log n)$ (järjestäminen)}

Aikavaativuus $O(n \log n)$ viittaa usein siihen,
että algoritmin osana on \emph{järjes\-tämistä},
koska tehokkaat järjestämisalgoritmit
toimivat ajassa $O(n \log n)$.
Esimerkiksi seuraava $O(n \log n)$-aikainen
algoritmi tarkastaa, onko taulukossa kahta samaa alkiota:

\begin{code}
sort(taulu) // järjestäminen
samat = false
for i = 1 to n-1
    if taulu[i] == taulu[i-1]
        samat = true
\end{code}

Algoritmi järjestää ensin taulukon, minkä jälkeen yhtä
suuret alkiot ovat vierekkäin ja ne on helppoa löytää.
Järjestäminen vie aikaa $O(n \log n)$
ja silmukka vie aikaa $O(n)$, joten algoritmi vie
yhteensä aikaa $O(n \log n)$.

Tutustumme tarkemmin järjestämiseen ja sitä käyttäviin
algoritmeihin seuraavassa luvussa 3.

\index{neliöllinen algoritmi}

\subsubsection{$O(n^2)$ (neliöllinen)}

\emph{Neliöllinen} (\emph{quadratic}) algoritmi voi käydä läpi kaikki tavat valita
kaksi alkiota syöt\-teestä.
Esimerkiksi seuraava $O(n^2)$-algoritmi tutkii, onko taulukossa
kahta lukua, joiden summa on $x$.

\begin{code}
ok = false
for i = 0 to n-1
    for j = i+1 to n-1
        if taulu[i]+taulu[j] == x
            ok = true
\end{code}

\index{kuutiollinen algoritmi}

\subsubsection{$O(n^3)$ (kuutiollinen)}

\emph{Kuutiollinen} (\emph{cubic}) algoritmi voi käydä läpi kaikki tavat valita
kolme alkiota syöt\-teestä.
Esimerkiksi seuraava $O(n^3)$-algoritmi tutkii, onko taulukossa
kolmea lukua, joiden summa on $x$.

\begin{code}
ok = false
for i = 0 to n-1
    for j = i+1 to n-1
        for k = j+1 to n-1
            if taulu[i]+taulu[j]+taulu[k] == x
                ok = true
\end{code}

\subsubsection{$O(2^n)$ (osajoukot)}

Aikavaativuus $O(2^n)$ viittaa usein siihen,
että algoritmi käy läpi syötteen alkioiden osajoukot.

\subsubsection{$O(n!)$ (permutaatiot)}

Aikavaativuus $O(n!)$ viittaa usein siihen,
että algoritmi käy läpi syötteen alkioiden permutaatiot.

\subsection{Tehokkuuden arviointi}

Mitä hyötyä on määrittää algoritmin aikavaativuus?
Hyötynä on, että aikavaativuus antaa arvion siitä,
kuinka \emph{hyvä} algoritmi on eli miten suuria syötteitä
sillä voi käsitellä tehokkaasti.
Aikavaativuuden avulla algoritmin tehokkuudesta pystyy saamaan
hyvän käsityksen ennen algoritmin toteuttamista ja testaamista käytännössä.

Aikavaativuutta voi ajatella samalla tavalla kuin
hotellin tähti\-luokitusta: se kertoo tiiviissä muodossa,
mistä asiassa on kysymys, eikä tarvitse ottaa selvää yksityiskohdista.
Jos majoitus on neljän tähden hotellissa,
tämä antaa heti jonkin käsityksen huoneen tasosta,
vaikka tiedossa ei olisi tarkkaa listausta huoneen varustelusta.
Vastaavasti jos jonkin algoritmin aikavaativuus on $O(n \log n)$,
tämän perusteella voi heti arvioida karkeasti,
miten suuria syötteitä algoritmi pystyy käsittelemään,
vaikka algoritmin kaikki yksityiskohdat eivät olisi tiedossa.

\begin{table}
\center
\begin{tabular}{rrr}
syötteen kokoluokka $n$ & tarvittava aikavaativuus \\
\hline
10 & $O(n!)$ \\
20 & $O(2^n)$ \\
500 & $O(n^3)$ \\
5000 & $O(n^2)$ \\
$10^6$ & $O(n)$ tai $O(n \log n)$ \\
suuri & $O(1)$ tai $O(\log n)$ \\
\end{tabular}
\caption{Kuinka suuren syötteen algoritmi voi käsitellä nopeasti?}
\label{tab:algteh}
\end{table}

Yksi kiinnostava näkökulma algoritmin tehokkuuteen on,
miten suuren syötteen algoritmi voi käsitellä \emph{nopeasti}
(noin sekunnissa).
Tämä on hyvä vaatimus, kun haluamme käyttää algoritmia
jossakin käytännön sovelluksessa.
Taulukossa \ref{tab:algteh} on joitakin hyödyllisiä arvioita,
kun algoritmi suoritetaan nykyaikaisella tietokoneella.
Esimerkiksi jos meillä on $O(n^2)$-algoritmi, voimme käsitellä sillä
nopeasti syötteen, jossa on luokkaa 5000 alkiota.
Jos haluamme käsitellä tehokkaasti suurempia syötteitä,
meidän tulisi löytää $O(n)$- tai $O(n \log n)$-aikainen algoritmi.

Kannattaa silti pitää mielessä, että nämä luvut ovat vain arvioita ja algoritmin
todelliseen ajankäyttöön vaikuttavat monet asiat.
Saman algoritmin hyvä toteutus saattaa olla
kymmeniä kertoja nopeampi kuin huono toteutus,
ja suuri merkitys on myös ohjelmointikielellä,
jolla algoritmi on toteutettu.
Tässä kirjassa analysoimme algoritmeja sekä aikavaativuuksien
avulla että mittaamalla todellisia suoritusaikoja.

\subsection{Esimerkki: Merkkijonot}

Tehtävän ratkaisemiseen on usein monenlaisia algoritmeja.
Seuraavaksi ratkaisemme saman tehtävän kahdella algoritmilla,
joista ensimmäinen on suoraviivainen raa'an voiman
algoritmi, joka toimii ajassa $O(n^2)$.
Toinen algoritmi on puolestaan tehokas algoritmi,
joka vie aikaa vain $O(n)$.

Tehtävämme on seuraava: Annettuna on merkkijono,
jonka pituus on $n$ ja jokainen merkki on 0 tai 1.
Haluamme laskea, monellako tavalla voimme valita kaksi kohtaa
niin, että vasen merkki on 0 ja oikea merkki on 1.
Esimerkiksi merkkijonossa 01001 tapoja on neljä:
\underline{01}001, \underline{0}100\underline{1},
01\underline{0}0\underline{1} ja 010\underline{01}.

\subsubsection{$O(n^2)$-algoritmi}

Voimme ratkaista tehtävän raa'alla voimalla
käymällä läpi kaikki mahdolliset tavat valita vasen ja oikea kohta.
Tällöin voimme laskea yksi kerrallaan,
monessako tavassa vasen merkki on 0 ja oikea merkki on 1.
Seuraava koodi toteuttaa algoritmin:

\begin{code}
laskuri = 0
for i = 0 to n-1
    for j = i+1 to n-1
        if merkit[i] == 0 and merkit[j] == 1
            laskuri += 1
print(laskuri)
\end{code}

Algoritmin aikavaativuus on $O(n^2)$, koska siinä on kaksi
sisäkkäistä silmukkaa, jotka käyvät läpi syötteen.

\subsubsection{$O(n)$-algoritmi}

Kuinka voisimme ratkaista tehtävän tehokkaammin?
Meidän tulisi keksiä tapa, jolla saisimme
pois toisen silmukan koodista.

Tässä auttaa lähestyä ongelmaa hieman toisesta
näkökulmasta: kun olemme tietyssä kohdassa merkkijonoa,
monellako tavalla voimme muodostaa parin,
jonka oikea merkki on nykyisessä kohdassamme?
Jos olemme merkin 0 kohdalla, pareja ei ole yhtään,
mutta jos merkkinä on 1, voimme valita \emph{minkä tahansa}
vasemmalla puolella olevan merkin 0 pariin.

Tämän havainnon ansiosta riittää käydä läpi
merkkijono kerran vasemmalta oikealle ja pitää kirjaa,
montako merkkiä 0 olemme nähneet.
Sitten jokaisen merkin 1 kohdalla kasvatamme
vastausta tämänhetkisellä merkkien 0 määrällä.
Seuraava koodi toteuttaa algoritmin:

\begin{code}
laskuri = 0
nollat = 0
for i = 0 to n-1
    if merkit[i] == 0
        nollat += 1
    else
        laskuri += nollat
print(laskuri)
\end{code}

Algoritmissa on vain yksi silmukka, joka käy syötteen läpi,
joten sen aikavaativuus on $O(n)$.

\subsubsection{Algoritmien vertailua}

Meillä on nyt siis kaksi algoritmia, joiden aikavaativuudet ovat
$O(n^2)$ ja $O(n)$, mutta mitä tämä tarkoittaa käytännössä?
Saamme tämän selville toteuttamalla algoritmit jollakin
oikealla ohjelmointikielellä
ja mittaamalla niiden suoritusaikoja erikokoisilla syötteillä.

Taulukko \ref{tab:algver} näyttää vertailun tulokset,
kun algoritmit on toteutettu Javalla ja syötteinä
on satunnaisia merkkijonoja.
Pienillä $n$:n arvoilla molemmat algoritmit toimivat
hyvin tehokkaasti, mutta suuremmilla syötteillä on
nähtävissä huomattavia eroja.
Raakaan voimaan perustuva $O(n^2)$-algoritmi
alkaa hidastua selvästi testistä $n=10^4$ alkaen,
ja testissä $n=10^6$ emme jaksa enää odottaa algoritmin valmistumista.
Tehokas $O(n)$-algoritmi taas selvittää suuretkin testit
salamannopeasti.

\begin{table}
\center
\begin{tabular}{rrr}
syötteen koko $n$ & $O(n^2)$-algoritmi & $O(n)$-algoritmi \\
\hline
$10$ & 0.00 s & 0.00 s\\
$10^2$ & 0.00 s & 0.00 s\\
$10^3$ & 0.00 s & 0.00 s\\
$10^4$ & 0.14 s & 0.00 s \\
$10^5$ & 16.22 s & 0.00 s \\
$10^6$ & - - & 0.01 s \\
\end{tabular}
\caption{Algoritmien suoritusaikojen vertailu.}
\label{tab:algver}
\end{table}

Tämän kurssin jatkuvana teemana on luoda algoritmeja,
jotka toimivat tehokkaasti myös silloin, kun niille annetaan suuria syötteitä.
Tämä tarkoittaa käytännössä sitä, että algoritmin aikavaativuuden tulisi
olla $O(n)$ tai $O(n \log n)$.
Jos algoritmin aikavaativuus on esimerkiksi $O(n^2)$,
se on auttamatta liian hidas suurien syötteiden käsittelyyn.

\section{Lisää algoritmien analysoinnista}

Aikavaativuuksissa esiintyvä $O$-merkintä on yksi monista merkinnöistä,
joiden avulla voimme arvioida funktioiden kasvunopeutta.
Tutustumme seuraavaksi tarkemmin näihin merkintöihin.

\subsection{Merkinnät $O$, $\Omega$ ja $\Theta$}

\index{$O$-merkintä}
\index{$\Omega$-merkintä}
\index{$\Theta$-merkintä}

Algoritmien analysoinnissa usein esiintyviä merkintöjä ovat:

\begin{itemize}
\item \emph{Yläraja}: Funktio $g(n)$ on luokkaa $O(f(n))$, jos on olemassa vakiot $c$ ja $n_0$
niin, että $g(n) \le c f(n)$ aina kun $n \ge n_0$.
\item \emph{Alaraja}: Funktio $g(n)$ on luokkaa $\Omega(f(n))$, jos on olemassa vakiot $c$ ja $n_0$
niin, että $g(n) \ge c f(n)$ aina kun $n \ge n_0$.
\item \emph{Tarkka arvio}: Funktio $g(n)$ on luokkaa $\Theta(f(n))$, jos se on sekä luokkaa $O(f(n))$
että luokkaa $\Omega(f(n))$.
\end{itemize}

Vakion $c$ tarkoituksena on, että saamme arvion kasvunopeuden suuruusluokalle välittämättä
vakiokertoimista. Vakion $n_0$ ansiosta meidän riittää tarkastella
kasvunopeutta suurilla $n$:n arvoilla.
Voimme myös kirjoittaa $g(n)=O(f(n))$, kun haluamme ilmaista,
että funktio $g(n)$ on luokkaa $O(f(n))$,
ja vastaavasti $\Omega$- ja $\Theta$-merkinnöissä.

Kun sanomme, että algoritmi toimii ajassa $O(f(n))$, tarkoitamme, että se suorittaa
\emph{pahimmassa tapauksessa} $O(f(n))$ askelta.
Tämä on yleensä hyvä tapa ilmoittaa algoritmin tehokkuus,
koska silloin annamme takuun siitä, että algoritmin ajankäytöllä on tietty yläraja,
vaikka syöte olisi valittu mahdollisimman ikävästi algoritmin kannalta.

Tarkastellaan esimerkkinä seuraavaa algoritmia, joka laskee
taulukon lukujen summan:

\begin{code}
summa = 0
for i = 0 to n-1
    summa += taulu[i]
\end{code}

Tämä algoritmi toimii samalla tavalla riippumatta taulukon sisällöstä,
koska se käy aina läpi koko taulukon.
Niinpä yläraja ajankäytölle on $O(n)$ ja alaraja ajankäytölle on samoin $\Omega(n)$,
joten voimme sanoa, että algoritmi vie aikaa $\Theta(n)$ kaikissa tapauksissa.

Tarkastellaan sitten seuraavaa algoritmia, joka selvittää,
onko taulukossa lukua $x$:

\begin{code}
ok = false
for i = 0 to n-1
    if taulu[i] == x
        ok = true
        break
\end{code}

Tässä algoritmin pahin ja paras tapaus eroavat.
Ajankäytön yläraja on $O(n)$, koska algoritmi joutuu käymään
läpi kaikki taulukon alkiot silloin, kun luku $x$
ei esiinny taulukossa.
Toisaalta ajankäytön alaraja on $\Omega(1)$,
koska jos luku $x$ on taulukon ensimmäinen alkio,
algoritmi pysähtyy heti taulukon alussa.
Voimme myös sanoa, että algoritmi suorittaa pahimmassa
tapauksessa $\Theta(n)$ askelta ja parhaassa tapauksessa
$\Theta(1)$ askelta.

Huomaa, että $O$-merkinnän antama yläraja voi olla
\emph{mikä tahansa} yläraja, ei välttämättä tarkka yläraja.
On siis oikein sanoa esimerkiksi, että
algoritmi vie aikaa $O(n^2)$, vaikka on olemassa parempi yläraja $O(n)$.
Miksi sitten käytämme $O$-merkintää, vaikka voisimme usein myös ilmaista tarkan
ajankäytön $\Theta$-merkinnällä?
Tämä on vakiintunut ja käytännössä toimiva tapa.
Olisi hyvin harhaanjohtavaa antaa algoritmille yläraja $O(n^2)$,
jos näemme suoraan, että aikaa kuluu vain $O(n)$.

Asiaa voi ajatella niin, että $O$-merkintää käytetään algoritmin
\emph{markkinoinnissa}. Jos annamme liian suuren ylärajan, algoritmista
tulee väärä käsitys yleisölle.
Vertauksena jos myymme urheiluautoa, jonka huippunopeus on 250 km/h,
on sinänsä paikkansa pitävä väite, että autolla pystyy ajamaan 100 km/h.
Meidän ei kuitenkaan kannata antaa tällaista vähättelevää tietoa,
vaan kertoa, että autolla pystyy ajamaan 250 km/h.

Merkintöjä $O$, $\Omega$ ja $\Theta$ voi käyttää
kaikenlaisissa yhteyksissä, ei vain algoritmin ajankäytön arvioinnissa.
Esimerkiksi voimme sanoa, että algoritmi suorittaa silmukkaa $O(\log n)$ kierrosta
tai että listassa on $O(n)$ lukua.

\subsection{Tilavaativuus}

\index{tilavaativuus}

Aikavaativuuden lisäksi kiinnostava tieto algoritmista voi olla sen
\emph{tilavaativuus} (\emph{space complexity}). Tämä kuvaa sitä, miten paljon algoritmi
käyttää muistia syötteen \emph{lisäksi}.
Jos tilavaativuus on $O(1)$, algoritmi tarvitsee muistia
vain yksittäisille muuttujille.
Jos tilavaativuus on $O(n)$, algoritmi voi varata esimerkiksi aputaulukon,
jonka koko vastaa syötteen kokoa.

Tarkastellaan esimerkkinä tehtävää, jossa taulukossa on
luvut $1,2,\dots,n$ yhtä lukuun ottamatta,
ja tehtävämme on selvittää puuttuva luku.
Yksi tapa ratkaista tehtävä $O(n)$-ajassa on luoda aputaulukko,
joka pitää kirjaa mukana olevista luvuista.
Tällaisen ratkaisun tilavaativuus on $O(n)$,
koska aputaulukko vie $O(n)$ muistia.

\begin{code}
for i = 0 to n-2
    mukana[taulu[i]] = true
for i = 1 to n
    if not mukana[i]
        puuttuva = i
\end{code}

Tehtävään on kuitenkin olemassa myös toinen algoritmi,
jossa aikavaativuus on edelleen $O(n)$ mutta tilavaativuus on vain $O(1)$.
Tällainen algoritmi laskee ensin lukujen $1,2,\dots,n$ summan
ja vähentää sitten taulukossa esiintyvät luvut siitä.
Jäljelle jäävä luku on puuttuva luku.

\begin{code}
summa = 0
for i = 1 to n
    summa += i
for i = 0 to n-2
    summa -= taulu[i]
puuttuva = summa
\end{code}

Huomaa, että muuttujien ja taulukoiden lisäksi myös \emph{rekursio}
voi viedä tilaa, koska rekursiivisen aliohjelman kutsuihin liittyvät
tiedot ovat muistissa rekursiopinossa.
Esimerkiksi seuraavan proseduurin tilavaativuus on $O(n)$,
koska muistissa on korkeimmillaan $n$ kerrosta rekursiivisia kutsuja.

\begin{code}
procedure f(n)
    if n == 1
        return
    f(n-1)
\end{code}



Käytännössä tilavaativuus on yleensä sivuroolissa algoritmeissa,
koska jos algoritmi vie vain vähän aikaa, se ei \emph{ehdi} käyttää kovin paljon muistia.
Erityisesti tilavaativuus ei voi olla suurempi kuin aikavaativuus.
Niinpä riittää tavallisesti keskittyä suunnittelemaan algoritmeja,
jotka toimivat nopeasti, ja vertailla algoritmien aikavaativuuksia.

\subsection{Rajojen todistaminen}

Jos haluamme todistaa täsmällisesti, että jokin raja pätee,
meidän täytyy löytää vakiot $c$ ja $n_0$, jotka osoittavat asian.
Jos taas haluamme todistaa, että raja ei päde,
meidän täytyy näyttää, että mikään vakioiden $c$ ja $n_0$ valinta ei ole kelvollinen.

Jos haluamme todistaa rajan pätemisen,
tämä onnistuu yleensä helposti valitsemalla vakio $c$
tarpeeksi suureksi ja arvioimalla summan osia ylöspäin tarvittaessa.
Esimerkiksi jos haluamme todistaa, että $3n+5 = O(n)$, meidän tulee löytää
vakiot $c$ ja $n_0$, joille pätee, että $3n+5 \le cn$ aina kun $n \ge n_0$.
Tässä tapauksessa voimme valita esimerkiksi $c=8$ ja $n_0=1$,
jolloin voimme arvioida $3n+5 \le 3n+5n=8n$, kun $n \ge 1$.

Jos haluamme todistaa, että raja ei päde, tilanne on hankalampi,
koska meidän täytyy näyttää, että ei ole olemassa \emph{mitään} kelvollista
tapaa valita vakioita $c$ ja $n_0$.
Tässä auttaa tyypillisesti vastaoletuksen tekeminen: oletamme,
että raja pätee ja voimme valita vakiot,
ja näytämme sitten, että tämä oletus johtaa ristiriitaan.

Todistetaan esimerkkinä, että $n^2 \neq O(n)$.
Jos pätisi $n^2=O(n)$, niin olisi olemassa vakiot $c$ ja $n_0$,
joille $n^2 \le cn$ aina kun $n \ge n_0$.
Voimme kuitenkin osoittaa, että tämä aiheuttaa ristiriidan.
Jos $n^2 \le cn$, niin voimme jakaa epäyhtälön molemmat puolet $n$:llä
ja saamme $n \le c$.
Tämä tarkoittaa, että $n$ on aina enintään yhtä suuri kuin vakio $c$.
Tämä ei ole kuitenkaan mahdollista, koska $n$ voi olla miten
suuri tahansa, joten ei voi päteä $n^2 = O(n)$.

Määritelmistä lähtevä todistaminen on sinänsä mukavaa ajanvietettä,
mutta sille on äärimmäisen harvoin tarvetta käytännössä,
kun haluamme tutkia algoritmien tehokkuutta.
Voimme koko kurssin ajan huoletta päätellä algoritmin aikavaativuuden
katsomalla, mikä sen rakenne on, kuten olemme tehneet tämän luvun alkuosassa.
